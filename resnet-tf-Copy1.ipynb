{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk4BFA_wU-GE"
   },
   "source": [
    "1. 图片读取 dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in f:\\anaconda\\lib\\site-packages (2.2.2+cu118)\n",
      "Requirement already satisfied: torchvision in f:\\anaconda\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: torchaudio in f:\\anaconda\\lib\\site-packages (2.2.2+cu118)\n",
      "Requirement already satisfied: filelock in f:\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in f:\\anaconda\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in f:\\anaconda\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in f:\\anaconda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in f:\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in f:\\anaconda\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in f:\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in f:\\anaconda\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in f:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!conda install pytorch torchvision torchaudio pytorch-cuda==12.2 -c pytorch -c nvidia\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MFsRq3rm6FHT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "dataset = ImageFolder(root='./images/', transform=transform)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-xeXh9cAD8K"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 290939,
     "status": "error",
     "timestamp": 1709514413403,
     "user": {
      "displayName": "qing yang",
      "userId": "18395643287176615289"
     },
     "user_tz": -480
    },
    "id": "PG4GlXuQ6aIV",
    "outputId": "9d2f8047-c516-4c35-e5f0-ecc127a21cd6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_save_path = 'mobilenet/resnet50.pth'\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, 12)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=0.001)\n",
    "num_epochs = 10  # 举例，可以根据需要调整\n",
    "resnet50 = resnet50.to('cuda:0')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet50.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    print(device)\n",
    "    train_correct = 0\n",
    "\n",
    "    train_total = 0\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        train_start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        outputs = resnet50(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权重\n",
    "        train_end_time = time.time()\n",
    "        print(f'Training completed in {train_end_time - train_start_time} seconds')\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    torch.save(resnet50.state_dict(), model_save_path)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Acc: {100 * train_correct / train_total}')\n",
    "\n",
    "    # 验证模型\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():  # 在验证过程中不计算梯度\n",
    "        resnet50.eval()  # 设置模型为评估模式\n",
    "        for j, (inputs, labels) in enumerate(tqdm(val_loader)):\n",
    "            train_start_time = time.time()\n",
    "            outputs = resnet50(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            train_end_time = time.time()\n",
    "            print(f'val completed in {train_end_time - train_start_time} seconds')\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgJTVBQdVCEt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import os\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "import keras.utils\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rb83KFk1VA4M"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "\n",
    "imageList = []\n",
    "labelList = []\n",
    "norm_size = 112\n",
    "datapath = './jpg灰度'\n",
    "path=os.path.join(datapath)\n",
    "image_names=os.listdir(path)\n",
    "image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8FMklrzoDM7"
   },
   "outputs": [],
   "source": [
    "file = open(\"image_names.txt\",'w')\n",
    "for fp in image_names:\n",
    "  file.write(str(fp))\n",
    "  file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x2KdafNVFLs"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "labelList = []\n",
    "imageList = []\n",
    "for image_name in image_names[:1000]:\n",
    "  image_full_path = os.path.join(path,image_name)\n",
    "  label = image_name.split('_')\n",
    "  label = int(label[0])\n",
    "  labelList.append(label)\n",
    "  image = cv2.imdecode(np.fromfile(image_full_path, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "  image = cv2.resize(image,(norm_size,norm_size),interpolation=cv2.INTER_LANCZOS4)\n",
    "  # if image.shape[2]>3:\n",
    "  #   image=image[:,:,:3]\n",
    "  #   print(image.shape)\n",
    "  image = img_to_array(image)\n",
    "  print('count:',count)\n",
    "  imageList.append(image)\n",
    "  count = count+1\n",
    "\n",
    "imageList = np.array(imageList)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i71wsyPKVhMM"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "print(labelList)\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "labelList = lb.fit_transform(labelList)\n",
    "print(labelList)\n",
    "print(lb.classes_)\n",
    "f = open('label_list.pickle',\"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dwfJbA9qCr7"
   },
   "outputs": [],
   "source": [
    "imageList.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zKeZVw8qH2k"
   },
   "outputs": [],
   "source": [
    "labelList.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJZf7CRDVloq"
   },
   "outputs": [],
   "source": [
    "trainX,valX,trainY,valY = train_test_split(imageList,labelList,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTljo9dTVrz7"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                  horizontal_flip=True)\n",
    "train_data = train_datagen.flow(trainX,trainY,batch_size=16,shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator=val_datagen.flow(valX,valY,batch_size=16,shuffle=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='resnet_best.hdf5',monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='val_accuracy',patience=10,verbose=1,factor=0.5,min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433941,
     "status": "ok",
     "timestamp": 1685519256391,
     "user": {
      "displayName": "qing yang",
      "userId": "18395643287176615289"
     },
     "user_tz": -480
    },
    "id": "lHDbOhnuWf6b",
    "outputId": "eb91167f-be34-4bba-deaf-bbb37b033673"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "net=ResNet50(include_top=False,weights='imagenet',input_tensor=None,input_shape=(112,112,3))\n",
    "x=net.output\n",
    "print(x.shape)\n",
    "x = Flatten()(x)\n",
    "print(x.shape)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(12,activation='softmax',name='softmax')(x)\n",
    "net_classfier =Model(inputs=net.input, outputs=output_layer)\n",
    "# for layer in net_final.layers[:freeze_layers]:\n",
    "#     layer.trainable = False\n",
    "# for layer in net_final.layers[freeze_layers:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "net_classfier.compile(optimizer=Adam(lr=1e-3),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(net_classfier.summary())\n",
    "\n",
    "net_classfier.fit(train_data,steps_per_epoch=trainX.shape[0]/batch_size,\n",
    "         validation_data=val_generator,\n",
    "         epochs=100,\n",
    "         validation_steps=valX.shape[0] / batch_size,\n",
    "         callbacks=[checkpointer, reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP4kVmSzwDZa"
   },
   "outputs": [],
   "source": [
    "net_classfier.save('resnet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKJlzYSEN6It5JgTQV5LV7",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
